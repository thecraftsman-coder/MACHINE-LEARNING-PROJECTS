{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffd302e-c062-4408-b635-5fbd258c268d",
   "metadata": {},
   "source": [
    "## Financial Inclusion in Africa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c84e4-5e2f-4429-a1cf-f0d5233a2120",
   "metadata": {},
   "source": [
    "In this Project, we'll work on the **'Financial Inclusion in Africa'** dataset that was provided as part of the Financial Inclusion in Africa hosted by the Zindi platform.\n",
    "\n",
    "Dataset description: The dataset contains demographic information and what financial services are used by approximately 33,600 individuals across East Africa. The ML model role is to predict which individuals are most likely to have or use a bank account.\n",
    "\n",
    "The term financial inclusion means:  individuals and businesses have access to useful and affordable financial products and services that meet their needs – transactions, payments, savings, credit and insurance – delivered in a responsible and sustainable way.\n",
    "\n",
    "\n",
    "https://i.imgur.com/UNUZ4zR.jpg\n",
    "\n",
    "\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Install the necessary packages\n",
    "2. Import you data and perform basic data exploration phase\n",
    "- Display general information about the dataset\n",
    "- Create a pandas profiling reports to gain insights into the dataset\n",
    "- Handle Missing and corrupted values\n",
    "- Remove duplicates, if they exist\n",
    "- Handle outliers, if they exist\n",
    "- Encode categorical features\n",
    "3. Based on the previous data exploration train and test a machine learning classifier\n",
    "4. Create a streamlit application (locally) and add input fields for your features and a validation button at the end of the form\n",
    "5. Import your ML model into the streamlit application and start making predictions given the provided features values\n",
    "6. Deploy your application on Streamlit share:\n",
    "- Create a github and a streamlit share accounts\n",
    "- Create a new git repo\n",
    "- Upload your local code to the newly created git repo\n",
    "- log in to your streamlit account an deploy your application from the git repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc4690-3291-4bf9-9254-685d35102208",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3bcec-dcd7-4ec9-8da8-aa69e8749c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5aa6f6-70fc-4d60-b57d-8e4b5424d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49377cd5-6143-4098-8293-ec0fa81cfe8f",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe5ff0-ab42-405f-8c42-e56ea4ef34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Financial_inclusion_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d675c0b-2d9e-49ea-b179-9551f6647c3e",
   "metadata": {},
   "source": [
    "#### Overview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b1e8b-0800-47f5-9438-66a432df1d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687b97f-5ee4-48d5-876b-68e02aa61821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59214dad-c2e3-4b1d-829c-27f49cef5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60222137-95dd-4461-919f-c847e62a8df4",
   "metadata": {},
   "source": [
    "##### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7e584-d5ed-400a-9db5-28c5f8682eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581df5b3-beda-4127-8fb0-defa42b177dc",
   "metadata": {},
   "source": [
    "##### Checking for missing values and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da9b74-dd0d-4db3-91da-6421c93cc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb76c30-178a-4ac8-97a4-445a2bd8622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ac006-337a-456f-8496-e8c1bcad7eea",
   "metadata": {},
   "source": [
    "No missing values and duplicates Cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5556fe-a747-4769-957b-ce3765855649",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79ab16-2853-4cfd-bfdd-a23f30891e2a",
   "metadata": {},
   "source": [
    "#### Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f40528-b15d-4116-8b07-12e18e31ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bank_account'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d43b7f-0238-41f2-9451-4a0bbf1c11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f284e0-2795-49e4-9760-99d1eab6c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cellphone_access'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c029e-3adf-487d-9ffd-4c3ed8544a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender_of_respondent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de7983-c5f8-4163-b54a-c9d41592c1fd",
   "metadata": {},
   "source": [
    "#### Binary Encoding with Binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc786529-bb9b-4f33-a491-5928bc005e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bank_account'] = df['bank_account'].map({'Yes': 1, 'No': 0})\n",
    "df['cellphone_access'] = df['cellphone_access'].map({'Yes': 1, 'No': 0})\n",
    "df['gender_of_respondent'] = df['gender_of_respondent'].map({'Female': 0, 'Male': 1})\n",
    "df['location_type'] = df['location_type'].map({'Rural': 0, 'Urban': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca864f8-cd8f-4cc8-81fc-7a7b2f68ccef",
   "metadata": {},
   "source": [
    "#### Multi-category Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc62ce1-d9b0-4b33-aeec-4b0c7a437f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marital_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc45acb-c02b-4e13-a82b-4d24f45c2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41223b36-fada-454a-9374-dbc49b4a4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a4d0ff-3cff-4449-8e27-be4269e9bfbc",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding for multi-category variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418df48-6547-4e49-aa10-5986a83e0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['job_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15d875-d6f7-4eec-b439-16772ca9b7df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035829b5-bc0a-47d6-ba1c-08ba0d295a46",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd7017-a5f5-449c-b916-10680e78c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1254966-7b21-4da4-891a-5dd14aa0c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_income'] = df[['job_type_Farming and Fishing', 'job_type_Formally employed Government', 'job_type_Formally employed Private', \n",
    "                       'job_type_Informally employed', 'job_type_Other Income', 'job_type_Self employed'  ]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692698c7-29c1-4522-a835-aca51f504e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_married'] = df['marital_status'].apply(lambda x: 1 if x == 'Married/Living together' else 0)\n",
    "df['is_single'] = df['marital_status'].apply(lambda x: 1 if x == 'Single/Never Married' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ee4da-4503-4b9e-85e2-eeeba0153569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating binary columns for each education level\n",
    "df['primary_education'] = df['education_level'].apply(lambda x: 1 if x == 'Primary education' else 0)\n",
    "df['no_education'] = df['education_level'].apply(lambda x: 1 if x == 'No formal education' else 0)\n",
    "df['secondary_education'] = df['education_level'].apply(lambda x: 1 if x == 'Secondary education' else 0)\n",
    "df['tertiary_education'] = df['education_level'].apply(lambda x: 1 if x == 'Tertiary education' else 0)\n",
    "df['vocational_training'] = df['education_level'].apply(lambda x: 1 if x == 'Vocational/Specialised training' else 0)\n",
    "df['other_education'] = df['education_level'].apply(lambda x: 1 if x == 'Other/Dont know/RTA' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7465e2e-a990-425b-acc2-4c68d69f24da",
   "metadata": {},
   "source": [
    "#### Correlation matrix to check linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a0624-1f75-42cc-bc0e-93d79b5ae13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only numeric columns for correlation\n",
    "numeric_df = df.select_dtypes(include=[float, int])\n",
    "correlation_matrix = numeric_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531c34c-b954-43d7-8e23-4f44e0ceafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad40ed-b24a-47bf-a2e0-5624cdf4c1da",
   "metadata": {},
   "source": [
    "#### Variance Threshold to eliminate low variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca8573-b106-4ef3-b053-65c293f61be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop(columns=['country', 'uniqueid', 'gender_of_respondent', 'relationship_with_head', 'marital_status', 'education_level', 'bank_account'])\n",
    "y = df['bank_account']\n",
    "\n",
    "# Create the VarianceThreshold object with a specified threshold\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "\n",
    "# Fit the model on the feature data\n",
    "X_var_thresh = selector.fit_transform(X)\n",
    "\n",
    "# Check which features remain\n",
    "remaining_features = X.columns[selector.get_support()]\n",
    "print(remaining_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ede6c2-b811-4fa7-bb63-c416a3c8695e",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a1010-4835-4832-be42-5750b0c6405a",
   "metadata": {},
   "source": [
    "#### Logistic Regression(Lasso- Least Absolute Shrinkage and Selection Operator) Embedded Method\n",
    "\n",
    "To select my best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617c134-f939-45bf-9c87-5135a8850163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee99253-4f3e-4945-a603-dada63248a09",
   "metadata": {},
   "source": [
    "Selecting my features and splitting the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06fa78-621a-4914-8d35-6878ac16d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['year', 'country', 'uniqueid', 'gender_of_respondent', 'relationship_with_head', 'marital_status', \n",
    "                    'education_level', 'vocational_training', 'bank_account', 'job_type_Remittance Dependent',])\n",
    "\n",
    "y = df['bank_account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7112dfb-9a72-43e9-b856-1233b590fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644acbb-c991-4b16-ab3c-4e2e5cb4fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02abf3db-8ff8-4037-b7ef-c31fab3da75e",
   "metadata": {},
   "source": [
    "This time we are using the logistic regression model with a penalty = l1 which is used to reduce loss or error in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30a6c0-01e2-44ec-b384-a06a93d3c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= LogisticRegression(penalty = 'l1', C = 1.0, solver = 'liblinear')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030fed4a-bf4e-4186-90f8-87330d735100",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc957b4e-8ee2-4483-b4f8-f490df2ac508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a2b7d-c431-4e73-a77a-c8d0221fde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = accuracy_score(y_pred, y_test)\n",
    "ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe321e1-f745-4831-b523-7e369f45389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_pred, y_test)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74990640-d02a-465d-a71d-f8caddace49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_pred, y_test)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d94a39-5849-4d7f-b176-848b740c52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18644752-84aa-4b95-9e17-ec29c2d6c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the figure and axis\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# 28 color definitions\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', \n",
    "          'black', 'pink', 'lightgreen', 'lightblue', 'gray', \n",
    "          'indigo', 'orange', 'salmon', 'purple', 'gold', \n",
    "          'silver', 'brown', 'violet', 'lime', 'teal', \n",
    "          'navy', 'maroon', 'olive', 'coral', 'chocolate', \n",
    "          'crimson', 'darkblue']\n",
    "\n",
    "weights, params = [], []\n",
    "\n",
    "# Loop through regularization strengths\n",
    "for c in np.arange(-4., 6.):\n",
    "    model2 = LogisticRegression(penalty='l1', C=10.**c, solver='liblinear', random_state=42)\n",
    "    model2.fit(X_train, y_train)\n",
    "    weights.append(model2.coef_)\n",
    "    params.append(10**c)\n",
    "\n",
    "weights = np.array(weights)\n",
    "\n",
    "# Plot each column's weights using the color list\n",
    "for column, color in zip(range(weights.shape[2]), colors):  # Use shape[2] for correct column size\n",
    "    plt.plot(params, weights[:, 0, column],  # Access weights by [:, 0, column] for 2D plot\n",
    "             label=X.columns[column],  # Ensure X.columns has the right size\n",
    "             color=color)\n",
    "\n",
    "# Add horizontal line at y=0\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('Weight coefficient')\n",
    "plt.xlabel('C (inverse regularization strength)')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Set the position of the legend\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(1.38, 1.03), ncol=1, fancybox=True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('lasso-path.pdf', dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8be5c-80a6-4846-87ea-0ca0b765df89",
   "metadata": {},
   "source": [
    "#### Saving my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7f515-6e61-4460-8fb3-a0af54445498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b6459-878a-4c61-ba93-5ba743ca8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'financialmodel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa5e14",
   "metadata": {},
   "source": [
    "### Create The Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c9e9a-869e-4285-89d3-7cf96966f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the file Expresso_Churn_Prediction_Streamlit_App.py in write mode\n",
    "with open(\"Financial_Inclusion_Prediction_Streamlit_App.py\", \"w\") as file:\n",
    "    # Writing the Streamlit code into the file\n",
    "    file.write(\"\"\"\n",
    "# Import necessary libraries\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = joblib.load(\"expressoModel.pkl\")  \n",
    "\n",
    "# Set up the Streamlit app\n",
    "st.title('Expresso Client Churn Prediction')\n",
    "st.write(\"This app predicts the churn probability for Expresso clients based on their behavior.\")\n",
    "\n",
    "\n",
    "# Input fields for user to enter feature values\n",
    "frequence_rech = st.number_input('Recharge Frequency (FREQUENCE_RECH)', min_value=1.0, max_value=114.0, value=11.44, step=1.0)\n",
    "revenue = st.number_input('Revenue (REVENUE)', min_value=1.0, max_value=165166.0, value= 5454.27, step=0.1)\n",
    "frequence = st.number_input('Frequency of usage (FREQUENCE)', min_value=1.0, max_value=91.0,value = 13.88, step=1.0)\n",
    "data_volume = st.number_input('Data Volume (DATA_VOLUME)', min_value=0.0, max_value=560933.0,value = 3165.06, step=0.1)\n",
    "on_net = st.number_input('On Net Usage (ON_NET)', min_value=0.0, max_value=20837.0,value = 272.18, step=1.0)\n",
    "orange = st.number_input('Orange Network Usage (ORANGE)', min_value=0.0, max_value=4743.0, value = 96.23, step=1.0)\n",
    "regularity = st.number_input('Regularity of usage (REGULARITY)', min_value=0.0, max_value=1346.0, value=7.93, step=1.0)\n",
    "freq_top_pack = st.number_input('Frequency of Top Pack (FREQ_TOP_PACK)', min_value=1.0, max_value=320.0, value=9.20, step=1.0)\n",
    "\n",
    "# Create a dictionary with the input data\n",
    "input_data = {\n",
    "    'FREQUENCE_RECH': frequence_rech,\n",
    "    'REVENUE': revenue,\n",
    "    'FREQUENCE': frequence,\n",
    "    'DATA_VOLUME': data_volume,\n",
    "    'ON_NET': on_net,\n",
    "    'ORANGE': orange,\n",
    "    'REGULARITY': regularity,\n",
    "    'FREQ_TOP_PACK': freq_top_pack\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "# Predict churn probability using the loaded model\n",
    "if st.button('Predict Churn Probability'):\n",
    "    prediction = model.predict_proba(input_df)[:, 1]  # Probability of churn\n",
    "    churn_probability = round(prediction[0] * 100, 2)\n",
    "    st.write(f\"The predicted churn probability is {churn_probability}%\")\n",
    "\n",
    "# Option to display input data\n",
    "if st.checkbox('Show Input Data'):\n",
    "    st.write(input_df)\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7db2f-f82d-4010-94f8-f2abde913af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407e27f-fed4-4070-be56-0a9cb2458829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f048d3b-da79-4dec-97e9-c312e086fa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b60c7d-7336-402d-85db-dde318efe7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03f5fc-cc35-4a17-8049-f5624533892b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2c7a9-23f7-4cbb-ab1a-24d4c2b2a98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
